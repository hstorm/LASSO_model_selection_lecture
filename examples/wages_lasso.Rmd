---
title: 'R Example LASSO: Wages'
output:
  html_document:
    df_print: paged
---

R Example for the lecture: 
**Advanced model specification with LASSO** 

Guest Lecture: Advanced Applied Econometrics, Master of Agricultural and 
Food Economics, SS2023, Uni Bonn 
  
*Hugo Storm (hugo.storm@ilr.uni-bonn.de),  May 2023*

-----------------

This is an example of how to use LASSO for model selection when we are 
interested in a causal interpretation of the variables. In particularly 
we are interested in explaining the effects of schooling in wages. Note, this 
example should be understand only as in illustration of the approach, for 
actually deriving an effect of schooling on wages other aspects need 
to considered as well.

Data and example from Verbeek (2008) A Guide to Modern Econometrics (3th), 
section 3.4 



----------------
### For further details see:

**Double Selection: **
Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2014. “High-Dimensional Methods and Inference on Structural and Treatment Effects.” The Journal of Economic Perspectives 28 (2): 29–50.

**Technical into to glmnet package**


"An Introduction to glmnet" https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet.pdf


Hastie et al 2015. Statistical Learning with Sparsity, chapter "3.7 Computational Details and glmnet" pp. 50. http://web.stanford.edu/~hastie/StatLearnSparsity/



```{r}
library(glmnet)
library(plotmo) # for plot_glmnet
library(dplyr)

# Set random number seed
set.seed(20)

## Clear workspace 
rm(list = ls())
```

### Load Data
```{r}
#Import data as a data frame
dat<-read.csv("wages.csv", sep=";")
```

Have a look at the data. 

We have information about log wages (LOGWAGE) as well as some additional personal 
characteristics (see Verbeek for further details)
```{r}
dat
```

Get explanatory variables and create squared and cubed terms for experience
```{r}
dat$EXPER2 = dat$EXPER^2
dat$EXPER3 = dat$EXPER^3

XVars <- c("BLACK",
           "EXPER","EXPER2","EXPER3","HISP","MAR",
           "SCHOOL","UNION")

df <-dat[XVars]

```

### Run lasso on the model directly 

```{r}

lasso_mod <- glmnet(df,dat$LOGWAGE,alpha=1, family='gaussian')
plot_glmnet(lasso_mod, label=15)
```

Run cross-validation for model selection

```{r}
cvfit <- cv.glmnet(as.matrix(df),dat$LOGWAGE, nfolds =5)

plot(cvfit)
```
Get the model with the lowest error (indicated be the left vertical 
line in the plot)
```{r}

coef(cvfit ,s ="lambda.min")
```
```{r}
coef(cvfit ,s ="lambda.1se")
```
**Interpretation**
Consider what this result is telling us. From the cross validation plot 
we see that in terms of out-of-sample prediction a model including only one 
variable (SCHOOL) is not much worse (i.e. withing 1se of the best model)
then a model that includes all variables. So for a pure prediction 
(out-of-sample) perspective is it fine to simply use a model with only 
schooling included. If we would naively, following the Post-LASSO approach
we would now run an OLS regression using only schooling. Obviously, when 
considering the consequences of omitted variables this approach is highly 
problematic! 



## Double selection approach 


See: 
*Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2014. “High-Dimensional Methods and Inference on Structural and Treatment Effects.” The Journal of Economic Perspectives 28 (2): 29–50.*

Lets see how a double selection approach would work in this context. 
Remember that we are interested in estimating the effects of schooling on wage.
Hence in this example schooling is our "treatment" variable. 
In the double selection approach we first run two models. 
1) We explain wages by all control variables (except schooling)
2) We explain schooling by all the control variables
In each case we use LASSO for variable selection. 

Finally we run run OLS on the union of the variables selection in 1) and 2)

```{r}

```

First get all the exogenous variables (excluding SCHOOL)
```{r}
dfExog <- df[ , !names(df) %in% c("SCHOOL")]
```

### 1) Perform model selection explaining wages by all the exogenous variables 
(excluding schooling)
```{r}
# Run cross validation
cvfit_wageExog <- cv.glmnet(as.matrix(dfExog), dat$LOGWAGE,nfolds =20)

```

Get list of variables for "lambda.min"
```{r}
coefWagemin <- coef(cvfit_wageExog ,s ="lambda.min")
coefWagemin
lstCoefWagemin <- coefWagemin@Dimnames[[1]][which(coefWagemin != 0 ) ] #feature names: intercept included
lstCoefWagemin <- tail(lstCoefWagemin,-1) # exclude constant
lstCoefWagemin
```

Get list of variables for "lambda.1se" 
```{r}
coefWage1se <- coef(cvfit_wageExog ,s ="lambda.1se")
coefWage1se
lstCoefWage1se <- coefWage1se@Dimnames[[1]][which(coefWage1se != 0 ) ] #feature names: intercept included
lstCoefWage1se <- tail(lstCoefWage1se,-1) # exclude constant
lstCoefWage1se

```

### 2) Perform model selection explaining schooling by all the exogenous variables 


```{r}
# Run cross validation
cvfit_SCHOOL <- cv.glmnet(as.matrix(dfExog), dat$SCHOOL,nfolds =20)

```

Get list of variables for "lambda.min"
```{r}
coefSchoolmin <- coef(cvfit_SCHOOL ,s ="lambda.min")
coefSchoolmin
lstCoefSchoolmin <- coefSchoolmin@Dimnames[[1]][which(coefSchoolmin != 0 ) ] #feature names: intercept included
lstCoefSchoolmin <- tail(lstCoefSchoolmin,-1) # exclude constant
lstCoefSchoolmin

```

Get list of variables for "lambda.1se" 
```{r}
coefSchool1se <- coef(cvfit_SCHOOL ,s ="lambda.1se")
coefSchool1se
lstCoefSchool1se <- coefSchool1se@Dimnames[[1]][which(coefSchool1se != 0 ) ] #feature names: intercept included
lstCoefSchool1se <- tail(lstCoefSchool1se,-1) # exclude constant
lstCoefSchool1se
```
### Run the final model explaining wages by the union of variables selected in 1) and 2). 

Because we are worried about omitted variables bias lets take the variables 
selected from the "lambda.min" this includes more variables as "lambda.1se".
Because including too many variables is less of a problem then excluding 
relevant once we want to be more conservative here. 

```{r}
dfDouble <- dat[,union(union(lstCoefSchoolmin,lstCoefWagemin),c("LOGWAGE","SCHOOL"))]

reg_double <- lm(LOGWAGE ~ .,data=dfDouble)
summary(reg_double)

```
Compare that to the result that we would obtained for OLS on all variables
```{r}
reg_Full <- lm(LOGWAGE ~ .,data=dat)
summary(reg_Full)


```
**Interpretation** 
Note that this example is somewhat constructed. With only those few variables
in the first place we would hardly consider lasso for variable selection. 

Also the results from the Post-Lasso are quite sensitive, if you change the
random number seed or the number of folds in the cross validation Lasso excluded 
less variables. This seem to be a happen quite frequently that the Post-Lasso 
are sensitive results are sensitive to the seed and number of folds. Ideally 
you run the model selection procedure for many different random number seeds 
and different number of folds and then summarize the results (i.e. take all the 
variables that are selected in most of the runs, or all variables selected 
in any run).
Also we could opt to use the "lambda.min" rule for model selection 
in the Post-Lasso which would have left more variables in the model (actually in 
this specific run the model is exactly equal to the one we obtain with double 
selection, however, this is more a coincident and nothing that we can expect to 
happen in other settings). 

Anyway, hopefully this example is still useful to understand the difference 
between Post-Lasso and Double selection and helps to illustrate that you need 
to be careful when naively following the Post-Lasso selection procedure. 
